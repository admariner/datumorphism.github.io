<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Statistics on Datumorphism</title><link>/tags/statistics/</link><description>Recent content in Statistics on Datumorphism</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Tue, 27 Oct 2020 00:00:00 +0000</lastBuildDate><atom:link href="/tags/statistics/index.xml" rel="self" type="application/rss+xml"/><item><title>Statistical Hypothesis Testing</title><link>/wiki/statistical-hypothesis-testing/hypothesis-testing/</link><pubDate>Sun, 20 Jan 2019 00:00:00 +0000</pubDate><guid>/wiki/statistical-hypothesis-testing/hypothesis-testing/</guid><description>When we have a sample of the population, we immediately calculate the mean using the sample, say the result is $\mu_0$. Of course, the population mean $\mu_p$ is unknown and probably can never be known.
This specific sample mean $\mu_0$ is nothing but like an advanced educated guess. Then again, how do we know if our this specific sample mean $\mu_0$ is a faithful representation of the population mean? In fact, this question is not limited to mean.</description></item><item><title>Why Estimation Theory</title><link>/wiki/statistical-estimation/why-estimation-theory/</link><pubDate>Sun, 20 Jan 2019 00:00:00 +0000</pubDate><guid>/wiki/statistical-estimation/why-estimation-theory/</guid><description>In statistics, we work with samples. For example, the sample mean is easily calculated. However, it is the population mean that is more valuable.
Suppose we have one sample $S_i$, which is used to calculate the mean of the sample $\mu_i$. We have two key problems to solve at this moment.
Can we use this sample mean $\mu_i$ to represent the population mean $\mu_p$? How good is our estimations? To answer these questions, we need to work out the properties of the samples themselves and work out a theory to instruct us to infer population statistics from sample statistics.</description></item><item><title>What is Statistics</title><link>/wiki/statistics/what-is-statistics/</link><pubDate>Fri, 18 Jan 2019 00:00:00 +0000</pubDate><guid>/wiki/statistics/what-is-statistics/</guid><description>A Case Study We have a problem.
In our lab, we found a huge amount of similar robots on a planet (physical population). To know more about the weight of these robots (statistical population), we first need to choose some of them (physical sample), then obtain the weight of them (statistical sample).
To describe the data, we could calculate the mean of the weight. We found that the mean weight is 93kg (descriptive statistics).</description></item><item><title>Data Types and Level of Measurement in Machine Learning</title><link>/wiki/machine-learning/feature-engineering/data-types/</link><pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate><guid>/wiki/machine-learning/feature-engineering/data-types/</guid><description>Types of Data There are several debatable categorization methods of data.
The first widely spread theory, or level of measurement, is by S. Stevens. The theory categorizes data into four types, nominal, ordinal, interval, and ratio.
Other methods are proposed for other fields of research. For example, N. R. Chrisman proposed a different method for cartography. However, these are not generic enough for data science. They are more general than a specific field of research.</description></item><item><title>Machine Learning Basics</title><link>/wiki/machine-learning/basics/</link><pubDate>Fri, 07 Jun 2019 00:00:00 +0000</pubDate><guid>/wiki/machine-learning/basics/</guid><description/></item><item><title>Types of Errors in Statistical Hypothesis Testing</title><link>/wiki/statistical-hypothesis-testing/type-1-error-and-type-2-error/</link><pubDate>Fri, 31 May 2019 00:00:00 +0000</pubDate><guid>/wiki/statistical-hypothesis-testing/type-1-error-and-type-2-error/</guid><description>Type I and Type II Errors In statistical hypothesis testing, we always have a null hypothesis $H_0$ which refers to the statement to be tested. We have two possible conclusions from a hypothesis testing,
to accept the hypothesis, that is concluding that $H_0$ is true, to reject the hypothesis, that is concluding that $H_0$ is false. However, it is possible that our conclusion is not correct. There are four possible results.</description></item><item><title>Confidence Interval</title><link>/wiki/statistical-estimation/confidence-interval/</link><pubDate>Sun, 20 Jan 2019 00:00:00 +0000</pubDate><guid>/wiki/statistical-estimation/confidence-interval/</guid><description>We will use upper cases for the abstract variable and lower cases for the actual numbers.
Why is Confidence Interval Needed? Suppose I sample the population multiple times, the mean value $\mu_i$ of the sample is calculated for each sample. It is a good question to ask how different these $\mu_i$ are compared to the true mean $\mu_p$ of the population.
In this article, we would need to specify several notations.</description></item><item><title>Jargons</title><link>/wiki/statistics/jargons/</link><pubDate>Sat, 24 Nov 2018 00:00:00 +0000</pubDate><guid>/wiki/statistics/jargons/</guid><description>Accuracy and Precision Accuracy: the measurement compared to the truth Precision: variability of repeated measurements; the more precise, the less variations during each measurement. Accurate Inaccurate Precise Close to true value, small variations in each measurement Far from true value, small variations in each measurement Imprecise Close to true value, large variations in each measurement Far from true value, large variations in each measurement Here is an example.</description></item><item><title>Chi-square Correlation Test for Nominal Data</title><link>/wiki/statistics/correlation-analysis-chi-square/</link><pubDate>Sun, 18 Nov 2018 00:00:00 +0000</pubDate><guid>/wiki/statistics/correlation-analysis-chi-square/</guid><description>In this article, we will discuss the chi-square correlation test for detecting correlations between two series.
Steps Find out all the possible values of the two nominal series A and B; Count the co-occurrences of the combinations (A, B); Calculate the expected co-occurrences of the combinations (A, B); Calculate chi-square; Determine whether the hypothesis can be rejected. Define the Series Suppose we are analyzing two series A and B.</description></item><item><title>Statistical Sign Test</title><link>/wiki/statistical-hypothesis-testing/sign-test/</link><pubDate>Sun, 20 Jan 2019 00:00:00 +0000</pubDate><guid>/wiki/statistical-hypothesis-testing/sign-test/</guid><description>We have a small dataset, but it doesn&amp;rsquo;t satisfy the t-test conditions. Then we would use as little assumptions as possible.
Wine Taste Suppose we have two bottles of wine, one of them is 300 euros while the other is 100 euros.
Now we ask the question:
Does expensive wine taste better?
We find 10 experts and give them some experiments. The result is recorded then processed into the following table.</description></item><item><title>Correlation Coefficient and Covariance for Numeric Data</title><link>/wiki/statistics/correlation-coefficient/</link><pubDate>Sun, 18 Nov 2018 00:00:00 +0000</pubDate><guid>/wiki/statistics/correlation-coefficient/</guid><description>Covariances Correlation coefficient is also known as the Pearson&amp;rsquo;s product moment coefficient. Review of Standard Deviation For a series of data A, we have the standard deviations
$$ \sigma_A = \sqrt{ \frac{ \sum (a_i - \bar A)^2 }{ n } }, $$
where $n$ is the number of elements in series A.
The standard deviation is very easy to understand. It is basically the average Eucleadian distance between the data points and the average value.</description></item><item><title>Mann-Whitney U Test</title><link>/wiki/statistical-hypothesis-testing/mann-whitney-u-test/</link><pubDate>Sun, 20 Jan 2019 00:00:00 +0000</pubDate><guid>/wiki/statistical-hypothesis-testing/mann-whitney-u-test/</guid><description>Mann-Whitney U is good at testing heavy-tailed data.</description></item><item><title>Normalization Methods for Numeric Data</title><link>/wiki/statistics/normalization-methods/</link><pubDate>Sun, 18 Nov 2018 00:00:00 +0000</pubDate><guid>/wiki/statistics/normalization-methods/</guid><description>Normalization of data is critical for statistical analysis and feature engineering.
Min-max Normalization This method is linear and straightforward.
Suppose we are analyzing series A, with elements $a_i$. We already know the min and max of the series, $a_{min}$ and $a_{max}$.
Now we would like to normalize the series to be within the range $[a_{min}', a_{max}']$. We simply solve the value of $a&amp;rsquo; _ i$ in $$ \frac{(a&amp;rsquo;_i - a_{min}')}{ ( a&amp;rsquo;_{max} - a&amp;rsquo;_{min} ) } = \frac{(a_i - a_{min})}{ ( a_{max} - a_{min} ) }, $$ where everything on the right hand side is known and $a_{min}&amp;lsquo;$ and $a_{max}&amp;lsquo;$ are chosen as the new min and max to be scaled to.</description></item><item><title>Linear Regression</title><link>/wiki/statistics/linear-regression/</link><pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate><guid>/wiki/statistics/linear-regression/</guid><description>In this article, we will use the Einstein summation convention. For example, $$ X_{ij}\beta_ j $$ is equivalent to $$ \sum_j X_{ij}\beta_ j $$ In statistics, we have at least three categories of quantities:
data and labels abstract theoretical quantities parameters and predictions of models The convention is that quantities with $\hat {}$ are the model quantities. Sometimes we do not distinguish the abstract theoretical quantities and model quantities.</description></item><item><title>Describing Multi-dimensional Data</title><link>/wiki/statistics/multidimensional-data/</link><pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate><guid>/wiki/statistics/multidimensional-data/</guid><description>Descriptions of Multidimensional Data Dispersion Matrix As defined in Correlation Coefficient and Covariance for Numeric Data, covariance is about the variance of two series. This property makes it easy to generalize it to multidimensional data.
The generalized quantity is named as dispersion matrix. Suppose we have a $p$ dimensional dataset $X$,
index $x_1$ $x_2$ &amp;hellip; $x_p$ 1 2.3 12.3 83.2 9.3 &amp;hellip; &amp;hellip; &amp;hellip; &amp;hellip; &amp;hellip; N 3.</description></item><item><title>Pattern Mining</title><link>/wiki/pattern-mining/</link><pubDate>Sun, 06 Jan 2019 00:00:00 +0000</pubDate><guid>/wiki/pattern-mining/</guid><description/></item><item><title>Statistical Estimation</title><link>/wiki/statistical-estimation/</link><pubDate>Sun, 20 Jan 2019 00:00:00 +0000</pubDate><guid>/wiki/statistical-estimation/</guid><description/></item><item><title>Statistical Hypothesis Testing</title><link>/wiki/statistical-hypothesis-testing/</link><pubDate>Fri, 31 May 2019 00:00:00 +0000</pubDate><guid>/wiki/statistical-hypothesis-testing/</guid><description/></item><item><title>Statistics</title><link>/wiki/statistics/</link><pubDate>Fri, 18 Jan 2019 00:00:00 +0000</pubDate><guid>/wiki/statistics/</guid><description/></item><item><title>Survival Analysis</title><link>/wiki/survival-analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/wiki/survival-analysis/</guid><description/></item><item><title>Conditional Probability Table</title><link>/cards/statistics/conditional-probability-table/</link><pubDate>Tue, 27 Oct 2020 00:00:00 +0000</pubDate><guid>/cards/statistics/conditional-probability-table/</guid><description>The conditional probability table, aka CPT, is used to calculate conditional probabilities from a dataset.
Given a dataset with features $\mathbf X$ and their corresponding classes $\mathbf Y$, the conditional probabilities of each class given a certain feature value can be calculated using a CPT which in turn can be calculated using a contigency table.</description></item><item><title>Covariance Matrix</title><link>/cards/statistics/covariance-matrix/</link><pubDate>Tue, 10 Mar 2020 00:00:00 +0000</pubDate><guid>/cards/statistics/covariance-matrix/</guid><description>We use Einstein&amp;rsquo;s summation convention. Covariance of two discrete series $A$ and $B$ is defined as
$$ \text{Cov} ({A,B}) = \sigma_{A,B}^2 = \frac{ (a_i - \bar A) (b_i - \bar B) }{ n- 1 }, $$
where $n$ is the length of the series. The normalization factor is set to $1/(n-1)$ to mitigate the bias for small $n$.
One could show that
$$ \mathrm{Cov}({A,B}) = E( A,B ) - \bar A \bar B.</description></item><item><title>Jackknife Resampling</title><link>/cards/statistics/jacknife-resampling/</link><pubDate>Sun, 26 Jan 2020 00:00:00 +0000</pubDate><guid>/cards/statistics/jacknife-resampling/</guid><description>Jackknife resampling is a method for estimation of the mean and higher order moments.
Given a sample $\{x_i\}$ of size $n$ for the distribution $X$, the jackknife resampling estimates the mean by leaving out each data point systematically. $n$ estimations of the mean will be obtained, with each of the estimations $x_i$
$$ \bar x_i = \frac{1}{n-1} \sum_{j\neq i} x_j. $$
The mean of the sample is
$$ \bar x = \frac{1}{n}\sum_i \bar x_i = \frac{1}{n} \sum_i \left(\frac{1}{n-1} \sum_{j\neq i} x_j\right) = \frac{1}{n}\sum_i x_i.</description></item><item><title>Kendall Tau Correlation</title><link>/cards/statistics/kendall-correlation-coefficient/</link><pubDate>Sat, 20 Jul 2019 00:00:00 +0000</pubDate><guid>/cards/statistics/kendall-correlation-coefficient/</guid><description>Definition two series of data: $X$ and $Y$ cooccurance of them: $(x_i, x_j)$, and we assume that $i&amp;lt;j$ concordant: $x_i &amp;lt; x_j$ and $y_i &amp;lt; y_j$; $x_i &amp;gt; x_j$ and $y_i &amp;gt; y_j$; denoted as $C$ discordant: $x_i &amp;lt; x_j$ and $y_i &amp;gt; y_j$; $x_i &amp;gt; x_j$ and $y_i &amp;lt; y_j$; denoted as $D$ neither concordant nor discordant: whenever equal sign happens Kendall&amp;rsquo;s tau is defined as
$$ \begin{equation} \tau = \frac{C- D}{\text{all possible pairs of comparison}} = \frac{C- D}{n^2/2 - n/2} \end{equation} $$</description></item><item><title>Bayes' Theorem</title><link>/cards/statistics/bayes-theorem/</link><pubDate>Tue, 18 Jun 2019 00:00:00 +0000</pubDate><guid>/cards/statistics/bayes-theorem/</guid><description>Bayes&amp;rsquo; Theorem is stated as
$$ P(A\mid B) = \frac{P(B \mid A) P(A)}{P(B)} $$
$P(A\mid B)$: likelihood of A given B $P(A)$: marginal probability of A There is a nice tree diagram for the Bayes&amp;rsquo; theorem on Wikipedia.
Tree diagram of Bayes&amp;rsquo; theorem</description></item><item><title>Poisson Process</title><link>/cards/statistics/poisson-process/</link><pubDate>Tue, 18 Jun 2019 00:00:00 +0000</pubDate><guid>/cards/statistics/poisson-process/</guid><description>Poisson Process Statistics // define getUnixTime Date.prototype.getUnixTime = function () { return this.getTime() / 1000 | 0 }; if (!Date.now) Date.now = function () { return new Date(); } Date.time = function () { return Date.now().getUnixTime(); } POISSON_EVENT_RATE = 1 function get_event_time() { var time = new Date(); return time } all_event = [] all_event_diff = [] var data = [{ x: [get_event_time], y: [1], mode: 'markers', line: { color: '#80CAF6' } }] var layout = { title: { text: 'Poisson Process' }, xaxis: { title: { text: 'Event Time' }, } }; var layout_rate = { title: { text: 'Average Rate of the Poisson Process' }, xaxis: { title: { text: 'Event Time' }, }, yaxis: { title: { text: 'Average Event Rate per Second' }, rangemode: 'tozero' } }; var data_rate = [{ x: [get_event_time], y: [POISSON_EVENT_RATE], mode: 'lines+markers', line: { color: '#80CAF6' } }] Plotly.</description></item><item><title>Controlled Experiments</title><link>/til/statistics/controlled-experiments/</link><pubDate>Tue, 04 Dec 2018 00:00:00 +0000</pubDate><guid>/til/statistics/controlled-experiments/</guid><description>The three levels of controlled experiments</description></item><item><title>Schaum's Outline of Theories and Problems of Elements of Statistics I and II</title><link>/reading/elements-of-statistics/</link><pubDate>Thu, 01 Nov 2018 00:00:00 +0000</pubDate><guid>/reading/elements-of-statistics/</guid><description>The basics and all of modern statistics</description></item></channel></rss>